\documentclass{ci5652}
\usepackage{graphicx,amssymb,amsmath}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{paralist}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

%----------------------- Macros and Definitions --------------------------

% Add all additional macros here, do NOT include any additional files.

% The environments theorem (Theorem), invar (Invariant), lemma (Lemma),
% cor (Corollary), obs (Observation), conj (Conjecture), and prop
% (Proposition) are already defined in the ci5652.cls file.

\graphicspath{ {plots/} }

%----------------------- Title -------------------------------------------

\title{Problema de selección de prototipo (IS/PS):\\ 
       Un enfoque con metaheurísticas}

\author{Juan Carlos Arocha Ovalles
        \and
        Matteo José Ferrando Briceño}

%------------------------------ Text -------------------------------------

\begin{document}
\thispagestyle{empty}
\maketitle


\begin{abstract}
El uso de clasificadores para determinar la clase de algún \textit{documento} está intimamente relacionado con el conjuntos de datos \textit{TR} con el que son entrenados. Un TR que represente adecuadamente a la muestra contiene potencialmente una gran cantidad de instancias, lo que genera un entrenamiento y una clasificación lenta. El objetivo de este estudio es encontrar un subconjunto de TR considerablemente más pequeño y con la misma capacidad de entrenamiento, es decir, que un clasificador que entrene con dicho subconjunto arroje los mismos resultado que entrenando con el TR original.


\end{abstract}

\section{Problema de selección de prototipo}

En el campo de clasificación de documentos, la calidad de clasificadores como \textit{K-NN} depende del TR con el cual sean entrenados. Un problema que se encuentra a la hora de elegir el TR es la selección de las intancias que lo conforman. Una gran cantidad instancias que representen las diferentes clases, pueden llevar a una buena clasificación, pero a su vez llevan a un entrenamiento y a un desempeño lento por parte de los clasificadores.

Es por ello que se ha intentado reducir este conjunto para disminuir el tiempo de entrenamiento y clasificación, pero manteniendo la calidad de los resultados que se obtengan.

Este problema es bastante común en diversas áreas de ciencias de la computación, por ejemplo, procesamiento y etiquetado de imágenes, análisis de \textit{big data}, análisis de lenguaje natural, \textit{Data Mining}, entre otros por lo que ha sido bastante estudiado y existen diversas soluciones propuestas.

\section{Trabajos anteriores}
\label{sect:works}

Entre las soluciones que se estudiaron en el estado del arte, en~\cite{toussaint2002proximity} Toussaint describe soluciones de tipo \textit{Greedy} como CNN, RNN y MCNN, las cuales demuestran una baja complejidad de tiempo y cuyos resultados son aceptables pero no optimales.Cano y Herrera en ~\cite{1255391}, proponen utiliazr algoritmos evolutivos solucionar el problema de selección de instancias para extracción de conocimientos en bases de datos (KDD), presentan una función de evaluación de calidad que se utilizaron para las pruebas; finalmente, concluyen que para KDD, los algoritmos evolutivos mejoran tanto la reducción del subconjunto, como la presición. Luego García y Derrac, con apoyo de Cano y Herrera, en ~\cite{garcia2012prototype} hacen un análisis extenso de los diversos algritmos basados en el algoritmo \textit{K-NN}. 

\section{Metaheurísticas}
\label{sect:meta}

Como se vió en~\cite{1255391}, una forma de resolver el problema IS/PS es usando metaheurísticas. Una metaheurística es un método genérico de solución de problemas computacionales, que no toma en cuenta el enunciado del problema sino la representación de sus soluciones, para luego mejorarlas en un tiempo eficiente pero que no asegura la optimalidad.

La mayoría de las metaheurísticas parten de una solución inicial, y a través de métodos iterativos, mejoran dicha solución, manteniendo la mejor de todas vista hasta el momento. La condición de parada de las mismas suelen variar entre un límite de tiempo, de iteraciones o que el espacio de búsqueda no provea mejores soluciones.

Para poder realizar pruebas usando metaheurísticas, se necesita una representación de la solución del problema planteado. En este caso, IS/PS fue representado con dos conjuntos: \textbf{SP} que corresponde a las instancias que se encuentran dentro del subconjunto de TR seleccionado y \textbf{UP} que corresponde al resto de las instancias que no están en el mismo. Por otro lado, también es necesario tener una funcion que sea capaz de evaluar una solución y que de este modo dos soluciones sean comparables. Como se vió en la sección~\ref{sect:works}, la calidad del subconjunto de TR seleccionado depende de la calidad de clasificación y del tamaño del mismo. La calidad se puede representar como el porcentaje de documentos bien clasificados, y el tamaño como el porcentaje de reducción de TR, lo que genera una función con dos variables. Para los experimentos se propusieron tres funciones:

\begin{equation}\label{eq:weight}
f(cl,rd) = \alpha\times cl + (1 - \alpha)\times rd
\end{equation}

\begin{equation}\label{eq:sqr}
f(cl,rd) = cl^{2}\times rd^{2}
\end{equation}

\begin{equation}\label{eq:exp}
f(cl,rd) = \beta^{cl\times rd}
\end{equation}

Donde $cl$ corresponde al porcentaje de classificación correcta, $rd$ al porcentaje de reducción de TR, $\alpha$ al peso en porcentaje (entre 0 y 1) que tiene $cl$ con respecto a $rd$ y $\beta$ a un número real arbitrario. La razón por la cual de toman estas funciones es porque se busca penalizar la puntuación obtenida por las mismas cuando cualquier de los dos atributos, sea $cl$ o $rd$, tengan valores muy bajos.

Por otra parte, también es necesario definir un operador de vecindad, el cual consiste en una función capaz de generar nuevas soluciones a partir de cualquier solución. El mismo depende de la metaheurística aplicada a problema.

En los experimentos realizados en este estudio, se consideró el uso de búsqueda local como metaheurística lineal y búsqueda local iterada y GRASP como metaheurísticas de trayectoria.

\section{Búsqueda local}

La búsqueda local consiste en partir de una solución inicial, que va a ser modificada por un operador de vecindad que genera otra solución factible. Luego, la solución actual se compara con la solución generada a través de una función de evaluación de calidad, y se desecha la peor de ambas para recurrir en el mismo proceso con la restante.

Como fue descrito en la sección~\ref{sect:meta}, se tomó la representación de \textbf{SP}y \textbf{UP} para las soluciones y las funciones de evaluación se tomaron las funciones~\ref{eq:sqr}, ~\ref{eq:weight} y~\ref{eq:exp}, .

Para ~\ref{eq:exp}, $\beta$ tomó el valor de \textit{Euler} por la forma en que la función exponencial crece. Como se puede ver en la figura~\ref{fig:euler3}, la misma penaliza a los valores más bajos, pues su crecimiento en ese punto es lento y a medida que los valores suben, el valor de la función crece de forma más violenta. En las figuras~\ref{fig:squared3} y~\ref{fig:weighted3} se puede notar que~\ref{eq:sqr} y~\ref{eq:weight} tienen un comportamiento parecido a~\ref{eq:exp} pero menos pronunciado. 

El operador de vencidad que se definió, consiste en una función que intercambia $K$ instancias entre \textbf{SP} y \textbf{UP} para generar nuevas soluciones, donde $K$ es un parámetro a calibrar dependiendo del problema de clasificación.

\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{SP, UP : Conjunto de puntos, K : Entero}
 \KwOut{SP', UP'}
 \ForEach{$1 \dots K$}{
  $sacar = booleano\_al\_azar()$\;
  \If{$sacar$}{
	$punto = punto\_al\_azar(SP)$\;
	$SP' = SP\ \backslash{}\ \{punto\}$\;
	$UP' = UP\ \cup\ \{punto\}$\;
  }
  \Else{
	$punto = punto\_al\_azar(UP)$\;
	$UP' = UP\ \backslash{}\ \{punto\}$\;
	$SP' = SP\ \cup\ \{punto\}$\;
  }
 }
 \vspace*{0.1cm}
 \caption{Operador de vecindad}
\end{algorithm}

% FIGURA DE FUNCIÓN POR PESO
\begin{figure}[p]
	\includegraphics[width=\linewidth]{weighted-3b}
	\caption{Pesada, ecuación~\ref{eq:weight}}
	\label{fig:weighted3}
\end{figure}
% FIGURA DE FUNCIÓN CUADRÁTICA
\begin{figure}[p]
	\includegraphics[width=\linewidth]{squared-3b}
	\caption{Cuadrática, ecuación~\ref{eq:sqr}}
	\label{fig:squared3}
\end{figure}
% FIGURA DE FUNCIÓN EULER
\begin{figure}[p]
	\centering
	\includegraphics[width=\linewidth]{euler-3b}
	\caption{Euler, ecuación~\ref{eq:exp}}
	\label{fig:euler3}
\end{figure}


\section{Búsqueda local iterada}
La búsqueda local iterada se trata de realizar una búsqueda local sobre una solución inicial, para obtener una mejor solución, la cual se perturba para generar una nueva solución inicial que se utiliza de forma recursiva realizando el mismo proceso. La solución perturbada puede ser mejor o peor que la solución generada por la búsqueda local, dado que lo que se quiere obtener al realizar dicha perturbación es expandir el espacio de búsqueda (lo que puede generar una solución peor pero que al realizar la búsqueda local sobre ella, lleve a un mínimo/máxmimo mejor que el encontrado) o minimizar/maximizar aún más la solución actual.

En los experimentos a realizar en esta metaheurística se tomaron en cuenta 2 formas de perturbación de soluciones:

\begin{itemize}
\item [\textbf{Perturbación aleatoria}:] Se perturba de forma aleatoria pero reservada, es decir, se cambia una pequeña cantidad de atributos al azar para que de esta forma la solución generada se mantenga en el mismo mínimo/máximo local que generó la última búsqueda local.
\item [\textbf{Perturbación \textit{Greedy}}:] Se perturba la solución con un algoritmo \textit{Greedy} como \textit{CNN }y \textit{MCNN}, los cuales generan soluciones aleatorias que pueden tener una cantidad de cambios considerables. Esta perturbación puede generar soluciones incluso peores que la inicial, pero que diversifica el espacio de búsqueda para acceder a otros mínimos/máximos. 
\end{itemize}

La idea detrás de estos tipos de perturbación es mejorar las soluciones que se puedan encontrar con el algoritmo. Una vez ejecutada una búsqueda local, existen dos escenarios posibles: El primero es que la búsqueda no llegó a generar el mínimo/máximo local, para lo cual se ejecuta el primer tipo de perturbación intentando así alcanzarlo. Y el segundo es que la búsqueda local sí consiguipo un mínimo/máximo local, por lo que es necesario salir del mismo para ampliar el espacio de búsqueda cayendo en el radio de búsqueda de otro mínimo o máximo local y para ello se ejecuta el segundo tipo de perturbación.

% FIGURA DE TIPOS DE PERTURBACIÓN
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{perturbaciones}
	\caption{Ejemplo de tipos de perturbación. Rojo: Perturbación aleatoria y resultado, Azul: Perturbación Greedy y resultado}
	\label{fig:euler3}
\end{figure}
\section{GRASP}
%\subsection{Resultados}
%\section*{Conclusiones}
%---------------------------- Bibliography -------------------------------

% Please add the contents of the .bbl file that you generate,  or add bibitem entries manually if you like.
% The entries should be in alphabetical order
\small
\bibliographystyle{abbrv}
\bibliography{informe}


% \newpage
% \section*{Apéndice}

\end{document}
