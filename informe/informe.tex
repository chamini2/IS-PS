\documentclass{ci5652}
\usepackage{graphicx,amssymb,amsmath}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{paralist}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

%----------------------- Macros and Definitions --------------------------

% Add all additional macros here, do NOT include any additional files.

% The environments theorem (Theorem), invar (Invariant), lemma (Lemma),
% cor (Corollary), obs (Observation), conj (Conjecture), and prop
% (Proposition) are already defined in the ci5652.cls file.

\graphicspath{ {plots/} }

%----------------------- Title -------------------------------------------

\title{Problema de selección de prototipo (IS/PS):\\ 
       Un enfoque con metaheurísticas}

\author{Juan Carlos Arocha Ovalles
        \and
        Matteo José Ferrando Briceño}

%------------------------------ Text -------------------------------------

\begin{document}
\thispagestyle{empty}
\maketitle


\begin{abstract}
El uso de clasificadores para determinar la clase de algún \textit{documento} está intimamente relacionado con el conjuntos de datos \textit{TR} con el que son entrenados. Un TR que represente adecuadamente a la muestra contiene potencialmente una gran cantidad de instancias, lo que genera un entrenamiento y una clasificación lenta. El objetivo de este estudio es encontrar un subconjunto de TR considerablemente más pequeño y con la misma capacidad de entrenamiento, es decir, que un clasificador que entrene con dicho subconjunto arroje los mismos resultado que entrenando con el TR original.


\end{abstract}

\section{Problema de selección de prototipo}

En el campo de clasificación de documentos, la calidad de clasificadores como \textit{K-NN} depende del TR con el cual sean entrenados. Un problema que se encuentra a la hora de elegir el TR es la selección de las intancias que lo conforman. Una gran cantidad instancias que representen las diferentes clases, pueden llevar a una buena clasificación, pero a su vez llevan a un entrenamiento y a un desempeño lento por parte de los clasificadores.

Es por ello que se ha intentado reducir este conjunto para disminuir el tiempo de entrenamiento y clasificación, pero manteniendo la calidad de los resultados que se obtengan.

Este problema es bastante común en diversas áreas de ciencias de la computación, por ejemplo, procesamiento y etiquetado de imágenes, análisis de \textit{big data}, análisis de lenguaje natural, \textit{Data Mining}, entre otros por lo que ha sido bastante estudiado y existen diversas soluciones propuestas.

\section{Trabajos anteriores}
\label{sect:works}

Entre las soluciones que se estudiaron en el estado del arte, en~\cite{toussaint2002proximity} Toussaint describe soluciones de tipo \textit{Greedy} como CNN, RNN y MCNN, las cuales demuestran una baja complejidad de tiempo y cuyos resultados son aceptables pero no optimales.Cano y Herrera en ~\cite{1255391}, proponen utiliazr algoritmos evolutivos solucionar el problema de selección de instancias para extracción de conocimientos en bases de datos (KDD), presentan una función de evaluación de calidad que se utilizaron para las pruebas; finalmente, concluyen que para KDD, los algoritmos evolutivos mejoran tanto la reducción del subconjunto, como la presición. Luego García y Derrac, con apoyo de Cano y Herrera, en ~\cite{garcia2012prototype} hacen un análisis extenso de los diversos algritmos basados en el algoritmo \textit{K-NN}. 

\section{Metaheurísticas}
\label{sect:meta}

Como se vió en~\cite{1255391}, una forma de resolver el problema IS/PS es usando metaheurísticas. Una metaheurística es un método genérico de solución de problemas computacionales, que no toma en cuenta el enunciado del problema sino la representación de sus soluciones, para luego mejorarlas en un tiempo eficiente pero que no asegura la optimalidad.

La mayoría de las metaheurísticas parten de una solución inicial, y a través de métodos iterativos, mejoran dicha solución, manteniendo la mejor de todas vista hasta el momento. La condición de parada de las mismas suelen variar entre un límite de tiempo, de iteraciones o que el espacio de búsqueda no provea mejores soluciones.

Para poder realizar pruebas usando metaheurísticas, se necesita una representación de la solución del problema planteado. En este caso, IS/PS fue representado con dos conjuntos: \textbf{SP} que corresponde a las instancias que se encuentran dentro del subconjunto de TR seleccionado y \textbf{UP} que corresponde al resto de las instancias que no están en el mismo. Por otro lado, también es necesario tener una funcion que sea capaz de evaluar una solución y que de este modo dos soluciones sean comparables. Como se vió en la sección~\ref{sect:works}, la calidad del subconjunto de TR seleccionado depende de la calidad de clasificación y del tamaño del mismo. La calidad se puede representar como el porcentaje de documentos bien clasificados, y el tamaño como el porcentaje de reducción de TR, lo que genera una función con dos variables. Para los experimentos se propusieron tres funciones:

\begin{equation}\label{eq:weight}
f(cl,rd) = \alpha\times cl + (1 - \alpha)\times rd
\end{equation}

\begin{equation}\label{eq:sqr}
f(cl,rd) = cl^{2}\times rd^{2}
\end{equation}

\begin{equation}\label{eq:exp}
f(cl,rd) = \beta^{cl\times rd}
\end{equation}

Donde $cl$ corresponde al porcentaje de classificación correcta, $rd$ al porcentaje de reducción de TR, $\alpha$ al peso en porcentaje (entre 0 y 1) que tiene $cl$ con respecto a $rd$ y $\beta$ a un número real arbitrario. La razón por la cual de toman estas funciones es porque se busca penalizar la puntuación obtenida por las mismas cuando cualquier de los dos atributos, sea $cl$ o $rd$, tengan valores muy bajos.

Por otra parte, también es necesario definir un operador de vecindad, el cual consiste en una función capaz de generar nuevas soluciones a partir de cualquier solución. El mismo depende de la metaheurística aplicada a problema.

En los experimentos realizados en este estudio, se consideró el uso de búsqueda local como metaheurística lineal y búsqueda local iterada y GRASP como metaheurísticas de trayectoria.

\section{Búsqueda local}\label{sect:ls}

La búsqueda local consiste en partir de una solución inicial, que va a ser modificada por un operador de vecindad que genera otra solución factible. Luego, la solución actual se compara con la solución generada a través de una función de evaluación de calidad, y se desecha la peor de ambas para recurrir en el mismo proceso con la restante.

Como fue descrito en la sección~\ref{sect:meta}, se tomó la representación de \textbf{SP}y \textbf{UP} para las soluciones y las funciones de evaluación se tomaron las funciones~\ref{eq:sqr}, ~\ref{eq:weight} y~\ref{eq:exp}, .

Para ~\ref{eq:exp}, $\beta$ tomó el valor de \textit{Euler} por la forma en que la función exponencial crece. Como se puede ver en la figura~\ref{fig:euler3}, la misma penaliza a los valores más bajos, pues su crecimiento en ese punto es lento y a medida que los valores suben, el valor de la función crece de forma más violenta. En las figuras~\ref{fig:squared3} y~\ref{fig:weighted3} se puede notar que~\ref{eq:sqr} y~\ref{eq:weight} tienen un comportamiento parecido a~\ref{eq:exp} pero menos pronunciado. 

Por otra parte, el operador de vencidad que se definió consiste en una función que intercambia $K$ instancias entre \textbf{SP} y \textbf{UP} para generar nuevas soluciones, donde $K$ es un parámetro a calibrar dependiendo del problema de clasificación.

Para la selección de las instancias a intercambiar, se tomaron en cuenta dos estrategias:

\begin{itemize}
\item \textbf{Selección aleatoria:} Se seleccionan puntos de forma aleatoria de alguno de los dos conjuntos \textbf{SP} o \textbf{UP}.
\item \textbf{Selección en base a costos:} Las instancias a intercambiar entre \textbf{SP} y \textbf{UP} son seleccionadas dependiendo de cuánto mejoren o empeoren la solución actual. Para determinar dicha medida, se define el \textit{costo incremental} $C(e)$ como una estimación del porcentaje de mejora a la solución al insertar la instancia $e$ a la misma y el \textit{costo decremental} $D(e)$ como una estimación de mejora a la solución al extraer la instancia $e$ de la misma. 

Para el caso específico de IS/PS, se tomaron dos definiciones de las función de costo incremental y decremental. 

\begin{itemize}
\item \textbf{Prueba por fuerza bruta:} En el caso de la función incremental $C(e)$, el valor se obtiene con la diferencia entre la evaluación de la solución que contiene al punto $e$ y la evaluación de la solución que no contiene al punto $e$. Y en el caso de la función decremental $D(e) = -C(e)$.

\item \textbf{Variación de posición del centroide:} En este caso se define la función incremental $C(e)$ como la variación de la posición del centroide de la clase de $e$, cuyo valor se considera mejor si es mayor. Y definimos la función decremental $D(e)$ igual que $C(e)$ pero en este caso su valor se considera mejor mientras sea menor.

\end{itemize}

La estrategia por fuerza bruta es la más convencional de las dos, puesto que obtiene el costo a partir de la función de evaluación definida para la búsqueda local y por ende asegura que la perturbación mejore la solución anterior. Pero por otro lado, se trata de un algoritmo con un orden de ejecución alto para la cantidad de veces que se podría repetir.

La estrategia de la distancia al centroide se trata de insertar puntos a la solución que modifiquen de una manera significativa la posición del centroide actual. Esto es porque una instancia que no modifique la posición del centroide de forma significativa, es una instancia cuyo valor no influye tanto a la hora de clasificar.
\end{itemize}

\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{SP, UP : Conjunto de puntos, K : Entero}
 \KwOut{SP', UP'}
 \ForEach{$1 \dots K$}{
  $sacar = booleano\_al\_azar()$\;
  \If{$sacar$}{
	$punto = punto\_al\_azar(SP)$\;
	$SP' = SP\ \backslash{}\ \{punto\}$\;
	$UP' = UP\ \cup\ \{punto\}$\;
  }
  \Else{
	$punto = punto\_al\_azar(UP)$\;
	$UP' = UP\ \backslash{}\ \{punto\}$\;
	$SP' = SP\ \cup\ \{punto\}$\;
  }
 }
 \vspace*{0.1cm}
 \caption{Operador de vecindad}
\end{algorithm}

% FIGURA DE FUNCIÓN POR PESO
\begin{figure}[p]
	\includegraphics[width=\linewidth]{weighted-3b}
	\caption{Pesada, ecuación~\ref{eq:weight}}
	\label{fig:weighted3}
\end{figure}
% FIGURA DE FUNCIÓN CUADRÁTICA
\begin{figure}[p]
	\includegraphics[width=\linewidth]{squared-3b}
	\caption{Cuadrática, ecuación~\ref{eq:sqr}}
	\label{fig:squared3}
\end{figure}
% FIGURA DE FUNCIÓN EULER
\begin{figure}[p]
	\centering
	\includegraphics[width=\linewidth]{euler-3b}
	\caption{Euler, ecuación~\ref{eq:exp}}
	\label{fig:euler3}
\end{figure}


\section{Búsqueda local iterada}
La búsqueda local iterada se trata de realizar una búsqueda local sobre una solución inicial para obtener una mejor solución, la cual se perturba para generar una nueva solución inicial que se utiliza para realizar el mismo proceso. La solución perturbada puede ser mejor o peor que la solución generada por la búsqueda local, dado que lo que se quiere obtener al realizar dicha perturbación es expandir el espacio de búsqueda (lo que puede generar una solución peor pero que al realizar la búsqueda local sobre ella, lleve a un valor mejor que el encontrado) o mejorar aún más la solución actual.

En los experimentos a realizar en esta metaheurística se tomaron en cuenta 2 formas de perturbación de soluciones:

\begin{itemize}
\item [\textbf{Perturbación aleatoria}:] Se perturba de forma aleatoria pero reservada, es decir, se cambia una pequeña cantidad de atributos al azar para que la solución generada se mantenga en la misma localidad que consiguió la última búsqueda local.
\item [\textbf{Perturbación \textit{Greedy}}:] Se perturba la solución con un algoritmo \textit{Greedy} como \textit{CNN }o \textit{MCNN}, los cuales generan soluciones aleatorias que pueden tener una cantidad de cambios considerables. Esta perturbación puede generar soluciones incluso peores que la inicial, pero que diversifica el espacio de búsqueda para acceder a otras localidades. 
\end{itemize}

La idea detrás de estos tipos de perturbación es mejorar las soluciones que se puedan encontrar con el algoritmo. Una vez ejecutada una búsqueda local, existen dos escenarios posibles: El primero es que la búsqueda no llegó a generar el mejor valor local, para lo cual se ejecuta el primer tipo de perturbación intentando así alcanzarlo. Y el segundo es que la búsqueda local sí consiguipo el mejor valor local, por lo que es necesario salir del mismo para ampliar el espacio de búsqueda cayendo en otra localidad de búsqueda y para ello se ejecuta el segundo tipo de perturbación. Para una referencia visual, ver la figura~\ref{fig:perturbaciones}

% FIGURA DE TIPOS DE PERTURBACIÓN
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{perturbaciones}
	\caption{Ejemplo de tipos de perturbación. Rojo: Perturbación aleatoria y resultado, Azul: Perturbación Greedy y resultado}
	\label{fig:perturbaciones}
\end{figure}

\section{\textit{\textbf{Greedy Randomized Adaptive Search Procedures}} (GRASP)}

GRASP (por sus siglas en inglés \textit{Greedy Randomized Adaptive Search Procedures}) es una metaheurística de trayectoria que trata de una forma aleatoria, recorrer la mayor cantidad de vecindades del espacio de búsqueda y de esa manera obtener la mejor solución. El algoritmo consiste generar una solución aleatoria a partir de un algoritmo \textit{greedy} y luego esta se le aplica una búsqueda local para intentar llegar a la mejor solución de esa vecindad, repitiendo este proceso $N$ veces guardando siempre la mejor solución (Véase el algoritmo~\ref{alg:grasp}). 

\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{N, Semilla : Entero}
 \KwOut{$S_{best}$}
 
 $f_{best} = \infty$\;
 \ForEach{$1 \dots N$}{
  $S = AlgoritmoGreedyAleatorio(Semilla)$\;
  $S = BusquedaLocal(S)$
  \If{$f(S) < f_{best}$}{
	$S_{best} = S$\;
	$f_{best} = f(S)$\;
   }
  }
 \vspace*{0.1cm}
 \caption{Algoritmo GRASP}
 \label{alg:grasp}
\end{algorithm}
La implementación en general es simple, pero lo que hace que sea efectivo o no es la generación de las soluciones aleatorias. La función que realiza esta tarea necesita definir una función de costo incremental para decidir cuál de los puntos que no está en la solución es el mejor candidato para ser añadido. En el caso de IS/PS, se tomó la función \textit{Variación de posición del centroide} definida en la sección~\ref{sect:ls}. Véase el algoritmo~\ref{alg:greedy-random-grasp} para más información.


\begin{algorithm}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{Semilla : Entero}
 \KwOut{$S_{best}$}
 $Candidatos = ConjuntoAleatorio()$\;
 $EvaluarCostoIncremental(e)|\forall e\in Candidatos$\;
 \While{$Candidatos\neq \emptyset$}{
 	$C_{min} = min\{C(e) | e \in C\}$\;	
 	$C_{max} = max\{C(e) | e \in C\}$\;	
 	$RCL = \{e\in C|C(e)\leq C_{min} +\alpha (C_{max} - C_{min})\}$\; 
 	$s = Aleatorio(RCL)$\;
 	$S_{best} = S_{best}\cup \{s\}$\;
 	$Candidatos = Candidatos\setminus \{s\}$\;
    $EvaluarCostoIncremental(e)|\forall e\in Candidatos$\;
 }
 \vspace*{0.1cm}
 \caption{Algoritmo GRASP}
 \label{alg:greedy-random-grasp}
\end{algorithm}
%\subsection{Resultados}
%\section*{Conclusiones}
%---------------------------- Bibliography -------------------------------

% Please add the contents of the .bbl file that you generate,  or add bibitem entries manually if you like.
% The entries should be in alphabetical order
\small
\bibliographystyle{abbrv}
\bibliography{informe}


% \newpage
% \section*{Apéndice}

\end{document}
